# The Moat for Generative AI, Trusted Data - Barr Moses

## Data Observability

Why are we all here? We all have access to models built by a bunch of people
with PhDs and with millions of dollars in CPUs.

In order to make Generative AI compelling and useful, we need proprietary data.
However, most folks are not very confident in delivering GenAI products.

While pretty much everyone feels pressure to build with generative AI and most
of them have caved to those expectations, most data leaders think their
executives have unrealistic expectations of GenAI.

Why do data leaders think we aren't ready?

While the tech has changed radically, data management hasn't changed very much.

Ten years ago, the most important thing for the business was their products
(e.g. websites, applications). Today, the most important thing is data, so
companies need more visibility into and control of their data

### Three core components

- Data Sources:

1. ingest
2. code that transforms and maintains data
3. data infrastructure

Problems with data can arise from any one of these three components.

More than half of folks surveyed, use manual rules-based systems to maintain the
state of the data.

Another proposed approach: data observability

### How this might work

- We need to have one unified view of the data

- We first need to detect that there's a problem, either with manual rules or AI

- Use AI and lineage to detect a root cause, not just a bug

- What if instead combing through logs to find the source of the bug, we had a
  system that supported us in correlating the bug to the root cause?

- When you're managing data products at scale, this isn't something that can be
  done manually.

- Not only can you have sophisticated detection, you can also do advanced alert
  routing to the correct teams or systems.

- Our challenge is to deliver GenAI products and build trust internally and
  externally, by automating detection, triage, alerting of data issues.
